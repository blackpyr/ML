机器学习的一些概念
 a.监督学习(supervised learning)
   从给定的训练数据集中学习出一个函数（模型参数），当新的数据到来时，可以根据这个函数预测结果。监督学习的训练集要求包括输入输出，
   也可以说是特征和目标。训练集中的目标是由人标注的。监督学习就是最常见的分类（注意和聚类区分）问题，通过已有的训练样本（即已知数据及其对应的输出）
   去训练得到一个最优模型（这个模型属于某个函数的集合，最优表示某个评价准则下是最佳的），再利用这个模型将所有的输入映射为相应的输出，
   对输出进行简单的判断从而实现分类的目的。也就具有了对未知数据分类的能力。监督学习的目标往往是让计算机去学习我们已经创建好的分类系统（模型）。
   监督学习是训练神经网络和决策树的常见技术。这两种技术高度依赖事先确定的分类系统给出的信息，对于神经网络，分类系统利用信息判断网络的错误，
   然后不断调整网络参数。对于决策树，分类系统用它来判断哪些属性提供了最多的信息。

   常见的有监督学习算法：回归分析和统计分类。最典型的算法是KNN和SVM。

   有监督学习最常见的就是：regression&classification
   回归(Regression）
      回归问题是针对于连续型变量的。
      回归通俗一点就是，对已经存在的点（训练数据）进行分析，拟合出适当的函数模型y=f(x)，
      这里y就是数据的标签，而对于一个新的自变量x，通过这个函数模型得到标签y。 
   分类（Classification)  
      和回归最大的区别在于，分类是针对离散型的，输出的结果是有限的。结果必定是离散的，只有“是”或“否”。

 b.无监督学习
   输入数据没有被标记，也没有确定的结果。样本数据类别未知，需要根据样本间的相似性对样本集进行分类（聚类，clustering）试图使类内差距最小化，
   类间差距最大化。通俗点将就是实际应用中，不少情况下无法预先知道样本的标签，也就是说没有训练样本对应的类别，
   因而只能从原先没有样本标签的样本集开始学习分类器设计。

   无监督学习目标不是告诉计算机怎么做，而是让它（计算机）自己去学习怎样做事情。
   无监督学习有两种思路。第一种思路是在指导Agent时不为其指定明确分类，而是在成功时，采用某种形式的激励制度。
   需要注意的是，这类训练通常会置于决策问题的框架里，因为它的目标不是为了产生一个分类系统，而是做出最大回报的决定，
   这种思路很好的概括了现实世界，agent可以对正确的行为做出激励，而对错误行为做出惩罚。

   无监督学习的方法分为两大类：

   (1)一类为基于概率密度函数估计的直接方法：指设法找到各类别在特征空间的分布参数，再进行分类。

   (2)另一类是称为基于样本间相似性度量的简洁聚类方法：其原理是设法定出不同类别的核心或初始内核，
      然后依据样本与核心之间的相似性度量将样本聚集成不同的类别。
   利用聚类结果，可以提取数据集中隐藏信息，对未来数据进行分类和预测。应用于数据挖掘，模式识别，图像处理等。

    PCA和很多deep learning算法都属于无监督学习。 
   
  两者的不同点
  1.有监督学习方法必须要有训练集与测试样本。在训练集中找规律，而对测试样本使用这种规律。而非监督学习没有训练集，只有一组数据，在该组数据集内寻找规律。
  2.有监督学习的方法就是识别事物，识别的结果表现在给待识别数据加上了标签。因此训练样本集必须由带标签的样本组成。而非监督学习方法只有要分析的数据集的本身，
    预先没有什么标签。如果发现数据集呈现某种聚集性，则可按自然的聚集性分类，但不予以某种预先分类标签对上号为目的。
  3.非监督学习方法在寻找数据集中的规律性，这种规律性并不一定要达到划分数据集的目的，也就是说不一定要“分类”。

   这一点是比有监督学习方法的用途要广。    譬如分析一堆数据的主分量，或分析数据集有什么特点都可以归于非监督学习方法的范畴。

  4.用非监督学习方法分析数据集的主分量与用K-L变换计算数据集的主分量又有区别。后者从方法上讲不是学习方法。
    因此用K-L变换找主分量不属于无监督学习方法，即方法上不是。而通过学习逐渐找到规律性这体现了学习方法这一点。
    在人工神经元网络中寻找主分量的方法属于无监督学习方法。 
 
 何时采用哪种方法
 
 简单的方法就是从定义入手，有训练样本则考虑采用监督学习方法；无训练样本，则一定不能用监督学习方法。
 但是，现实问题中，即使没有训练样本，我们也能够凭借自己的双眼，从待分类的数据中，人工标注一些样本，并把它们作为训练样本，
 这样的话，可以把条件改善，用监督学习方法来做。
 对于不同的场景，正负样本的分布如果会存在偏移（可能大的偏移，可能比较小），这样的话，监督学习的效果可能就不如用非监督学习了。
 
 *想法:
      在现实的生产环境中,往往都是在无监督学习开始的,因为很多业务都是从无到有,所以一开始一般都是通过收集一下相关的数据进行分析挖掘,所以没有明确的训练集
      和测试集,所以只能从无监督学习开始,当业务进行到一个阶段以后,开始收集到相关的业务数据,做成训练集和测试集,可以有无监督学习尝试转到监督学习,最后两者校对,
      选择最优的学习方法.
 
 
 b.泛化能力
   
 c.过拟合欠拟合(方差和偏差以及各自解决办法)
 d.交叉验证

线性回归的原理

线性回归
 a.损失函数
 b.代价函数
 c.目标函数
 
优化方法(梯度下降法、牛顿法、拟牛顿法等)
 a.梯度下降法
 b.牛顿法
 c.拟牛顿法
线性回归的评估指标

sklearn参数详解
